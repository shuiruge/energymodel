{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MB_UmMV7k4BK"
      },
      "outputs": [],
      "source": [
        "# If it's on colab:\n",
        "# !pip install git+https://github.com/shuiruge/energymodel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbSkSMwck24m"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from energymodel import (\n",
        "    EnergyModel, random_uniform, LossMonitor, FantasyParticleMonitor,\n",
        "    VectorFieldMonitor, LossGradientMonitor,\n",
        ")\n",
        "\n",
        "tf.compat.v1.reset_default_graph()\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kitxb9aAk24q"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxzxWfZWk24r"
      },
      "outputs": [],
      "source": [
        "(dataset, _), info = tfds.load(\n",
        "    'mnist',\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "def filter_img(image, label):\n",
        "    return image\n",
        "\n",
        "def normalize_img(image):\n",
        "    return 2 * tf.cast(image, 'float32') / 255 - 1\n",
        "\n",
        "def reshape_img(image):\n",
        "    return tf.reshape(image, [28*28])\n",
        "\n",
        "def preprocess_dataset(dataset, batch_size):\n",
        "    return (\n",
        "        dataset\n",
        "        .map(filter_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        .map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        .map(reshape_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        .cache()\n",
        "        .shuffle(info.splits['train'].num_examples)\n",
        "        .batch(batch_size)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "batch_size = 128\n",
        "dataset = preprocess_dataset(dataset, batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42qCNMp7k24r"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkXVS_gmk24s"
      },
      "outputs": [],
      "source": [
        "# We employ LeNet-like CNN as the network.\n",
        "# The activation function are changed from tanh to swish;\n",
        "# and the top dense layers are slightly adjusted. Output layer\n",
        "# has to be Dense(1, use_bias=False)\n",
        "network = models.Sequential([\n",
        "    layers.Reshape([28, 28, 1]),\n",
        "\n",
        "    layers.Conv2D(6, kernel_size=5, strides=1, padding='same'),\n",
        "    layers.Activation('swish'),\n",
        "    layers.AveragePooling2D(pool_size=2, strides=2, padding='valid'),\n",
        "\n",
        "    layers.Conv2D(16, kernel_size=5, strides=1, padding='valid'),\n",
        "    layers.Activation('swish'),\n",
        "    layers.AveragePooling2D(pool_size=2, strides=2, padding='valid'),\n",
        "\n",
        "    layers.Flatten(),\n",
        "\n",
        "    layers.Dense(256),\n",
        "    layers.Activation('swish'),\n",
        "\n",
        "    layers.Dense(64),\n",
        "    layers.Activation('swish'),\n",
        "\n",
        "    layers.Dense(1, use_bias=False),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKX1ornWk24s"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./logdir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0WnwHqck24t"
      },
      "outputs": [],
      "source": [
        "input_shape = [28*28]\n",
        "resample = lambda: random_uniform([batch_size, *input_shape])\n",
        "network(resample())  # build.\n",
        "\n",
        "model = EnergyModel(\n",
        "    network,\n",
        "    resample,\n",
        "    t=5e-0,\n",
        "    dt=1e-1,\n",
        ")\n",
        "tf.print('T = ', model.T)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(1e-3, clipvalue=1e-1)\n",
        "writer = tf.summary.create_file_writer('./logdir')\n",
        "callbacks = [\n",
        "    LossMonitor(writer, 5),\n",
        "    FantasyParticleMonitor(writer, model, 5),\n",
        "    VectorFieldMonitor(writer, model, 5),\n",
        "    LossGradientMonitor(writer, model, 5),\n",
        "]\n",
        "\n",
        "train_step = model.get_optimize_fn(optimizer, callbacks)\n",
        "train_step = tf.function(train_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8sFZ4QSl7rO"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logdir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7us7P1iJk24t"
      },
      "outputs": [],
      "source": [
        "# Two epochs are enough!\n",
        "for epoch in range(2):\n",
        "    for batch in tqdm(dataset):\n",
        "        train_step(batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0Cu4-btk24t"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3GPaoNCk24u"
      },
      "outputs": [],
      "source": [
        "test_X = list(dataset)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3BEpSMYk24u"
      },
      "outputs": [],
      "source": [
        "# If test denoise:\n",
        "noised_X = test_X + 0.5 * tf.random.truncated_normal(test_X.shape)\n",
        "\n",
        "# Or if test generation:\n",
        "# noised_X = random_uniform(test_X.shape)\n",
        "\n",
        "relaxed_X = model.evolve(noised_X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X592P9wqk24u"
      },
      "outputs": [],
      "source": [
        "def display_image(x):\n",
        "    x = x.numpy().reshape([28, 28])\n",
        "    plt.imshow(x)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQp05UG0k24v"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "display_image(test_X[i, :])\n",
        "# display_image(noised_X[i, :])\n",
        "display_image(relaxed_X[i, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62UEZNo9k24v"
      },
      "source": [
        "## Conclusions\n",
        "\n",
        "### Clipping\n",
        "We find that there's no need to do any clipping on the model, including that on vector field or on fantasy particles. The model can take care of itself! The only clipping may be about the optimizer.\n",
        "\n",
        "### Instability\n",
        "Instability may happen, but rarely. It comes from the optimizer, instead of from the model itself. Indeed, when instability appears, the loss diverges quickly, while the vector field values and fantasy particles are kept stable.\n",
        "\n",
        "### Persistance\n",
        "Using persistant random walk performs badly on both denoise and generation tasks. In high-dimensional phase space, the volumn of the space is quite large. Persistant random walk cannot explore the phase space efficiently, such that the fantasy particles dance in limited subspace. Contrarily, the non-persistant random walk explore the phase space with unreasonable efficiency, and performs greatly on both denoise and generation tasks."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Test Energy Model on MNIST.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 64-bit (system)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "667704c9cde27bc2120aa5af210b8dcad396b18ac5d66ebd3bcf266d25dea31f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
